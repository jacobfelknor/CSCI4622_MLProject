{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b0dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a51e2760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing snippets-all.csv...\n"
     ]
    }
   ],
   "source": [
    "# Extract top n words and full words from each file. Used for a stratified vocab and for documents to feed into tfidf\n",
    "def extract_words(filename, N):\n",
    "    print(f\"Processing {filename}...\")\n",
    "    df = pd.read_csv(filename)\n",
    "    # fill in missing values with an empty string\n",
    "    df = df.fillna(\"\")\n",
    "    top_words = [word for word, count in Counter(\" \".join(df[\"snippet\"]).lower().split()).most_common(N)]\n",
    "    words = df[\"snippet\"].tolist()\n",
    "    label = df[\"language\"].tolist()\n",
    "    return words, top_words, label\n",
    "\n",
    "#files = [\"snippets-bash.csv\", \"snippets-c.csv\", \"snippets-cpp.csv\", \"snippets-csv.csv\", \n",
    "#         \"snippets-dotfile.csv\", \"snippets-go.csv\", \"snippets-html.csv\", \"snippets-java.csv\", \"snippets-javascript.csv\",\n",
    "#         \"snippets-json.csv\"]\n",
    "files = [\"snippets-all.csv\"]\n",
    "\n",
    "# Loosely based off number of reserved keywords per language. Trying to upper bound to track most common keywords \n",
    "# and other common symbols in each language \n",
    "# https://stackoverflow.com/questions/4980766/reserved-keywords-count-by-programming-language\n",
    "N = 200\n",
    "\n",
    "vocabulary = []\n",
    "snippets = []\n",
    "labels = []\n",
    "for file in files:\n",
    "    snippet_list, vocab, label = extract_words(file, N)\n",
    "    vocabulary += vocab\n",
    "    snippets += snippet_list\n",
    "    labels += label\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f2e069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/files/normalise.jpg.png\\ntest/files/normalise-resized.jpg\\npackage-lock.json\\n/package.json\\n*.mongodb\\n', 'a computer network, with no transfer of a copy, is not conveying.\\n\\n  An interactive user interface displays \"Appropriate Legal Notices\"\\nto the extent that it includes a convenient and prominently visible\\nfeature that (1) displays an appropriate copyright notice, and (2)\\n', 'the predecessor has it or can get it with reasonable efforts.\\n\\n  You may not impose any further restrictions on the exercise of the\\nrights granted or affirmed under this License.  For example, you may\\nnot impose a license fee, royalty, or other charge for exercise of\\n', '  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\\n', \"const nconf = require('nconf');\\n\\nconst db = require('./mocks/databasemock');\\nconst helpers = require('./helpers');\\nconst Groups = require('../src/groups');\\n\"]\n",
      "['boolean', 'of', '2', 'new', '},']\n"
     ]
    }
   ],
   "source": [
    "print(snippets[:5])\n",
    "print(vocabulary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55bfea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boolean', 'of', '2', 'new', '},', 'void', 'using', '|', '4', '],', '(', '-', 'only', 'which', 'and', 'name', 'static', 'use', 'you', '2,', '/>', 'function', 'private', '3', 'false', '//', 'break;', '=', 'then', 'can', 'license.', 'do', 'false,', 'end', 'is', 'one', 'case', 'license', '<div', 'should', 'def', 'test', 'msgstr', '});', 'let', 'any', 'public', 'null)', 'be', 'source', '#', 'resolved', 'int', '===', 'char', 'i', 'true;', '\"author\":', '\"title\":', 'true,', 'version', 'the', 'that', 'see', 'typedef', '&', 'has', 'copyright', 'must', '|0', 'for', '\\\\', 'c', '>', '@override', '*', '#:', '1;', 'default', 'not', '};', '\"\"', 'x', 'distributed', 'error', '0x00,', ')', 'get', ':', 'a', 'when', '<<', '/**', 'an', '{', 'var', ':=', '\"version\":', 'on', 'list', 'nil', '[', '\"type\":', 'will', 'but', 'software', '}', '||', '1,', '#.', 'struct', 'code', 'if', '0,', 'true', 'else', 'object', 'at', '@param', '()', 'return', '0)', ');', ',', 'err', 'in', 'export', 'null;', 'bool', '0', '#define', 'may', '?', '///', '<', 'data', 'with', '0;', 'it', ']', 'we', 'const', 'module:', 'copy', 'false;', 'by', '#endif', 'result', 'are', 'null', 'namespace', 'unsigned', 'class', 'string', 'from', 'under', 'msgid', 'value', '&&', 'have', 'number', '*/', 'file', '\"', '=>', 'this', 'long', '+=', 'or', 'your', '+', 'null,', '->', 'more', '/*', 'all', '/', 'type', 'no', '!=', 'returns', '<a', 'final', 'to', 'name:', '#include', 'set', 'import', 'type:', 'used', '>=', '==', 'without', '\"id\":', '1', '})', 'typename', 'func', 'as', 'add']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X = vectorizer.fit_transform(snippets)\n",
    "# Lots of garbage in our features, e.g. '2', 'sherlock', '\"\",', 'carolina,south', '\"仄仄平平仄，平平仄仄平\"'\n",
    "# Could be improved by creating smarter tokens, or engineering the vocabulary a bit more. \n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccaf90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 41)\t1.0\n",
      "  (1, 183)\t0.16341492692682041\n",
      "  (1, 178)\t0.2540222823849807\n",
      "  (1, 143)\t0.2746496819198951\n",
      "  (1, 138)\t0.22133967429620074\n",
      "  (1, 136)\t0.21002905477423364\n",
      "  (1, 93)\t0.45693483173087457\n",
      "  (1, 79)\t0.20601576540346922\n",
      "  (1, 67)\t0.2605086464445217\n",
      "  (1, 62)\t0.44328038094254124\n",
      "  (1, 61)\t0.1448822384138086\n",
      "  (1, 34)\t0.17770093565570846\n",
      "  (1, 14)\t0.37632548332860516\n",
      "  (1, 1)\t0.1744958356981105\n",
      "  (2, 168)\t0.40934888369881856\n",
      "  (2, 165)\t0.11086403613928053\n",
      "  (2, 155)\t0.16676641418483068\n",
      "  (2, 138)\t0.28709925810907\n",
      "  (2, 136)\t0.1362141378376166\n",
      "  (2, 131)\t0.34535837350404613\n",
      "  (2, 98)\t0.14513948997563972\n",
      "  (2, 87)\t0.15516635851368693\n",
      "  (2, 79)\t0.2672226458911143\n",
      "  (2, 70)\t0.22386171309966488\n",
      "  (2, 66)\t0.17987030893528658\n",
      "  :\t:\n",
      "  (4849923, 162)\t0.9081163723807725\n",
      "  (4849923, 79)\t0.41871786947058554\n",
      "  (4849925, 152)\t0.24672147556909907\n",
      "  (4849925, 79)\t0.9690864324161217\n",
      "  (4849926, 152)\t0.24672147556909907\n",
      "  (4849926, 79)\t0.9690864324161217\n",
      "  (4849928, 162)\t1.0\n",
      "  (4849931, 152)\t0.24672147556909907\n",
      "  (4849931, 79)\t0.9690864324161217\n",
      "  (4849932, 152)\t1.0\n",
      "  (4849934, 79)\t1.0\n",
      "  (4849935, 3)\t1.0\n",
      "  (4849936, 177)\t1.0\n",
      "  (4849953, 177)\t0.7433495596399305\n",
      "  (4849953, 1)\t0.6689031560570793\n",
      "  (4849954, 125)\t1.0\n",
      "  (4849955, 162)\t1.0\n",
      "  (4849961, 79)\t1.0\n",
      "  (4849966, 79)\t1.0\n",
      "  (4849970, 125)\t1.0\n",
      "  (4849987, 99)\t1.0\n",
      "  (4849988, 99)\t1.0\n",
      "  (4849990, 99)\t1.0\n",
      "  (4849991, 79)\t1.0\n",
      "  (4849993, 49)\t1.0\n",
      "         0   1   2   3   4   5   6   7   8   9   ...  11  12  13  14  15  16  \\\n",
      "0         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "1         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "2         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "3         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "4849995   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4849996   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4849997   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4849998   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4849999   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "\n",
      "         17  18  19  20  \n",
      "0         0   0   1   0  \n",
      "1         0   0   0   1  \n",
      "2         0   0   0   1  \n",
      "3         0   0   0   1  \n",
      "4         0   0   0   0  \n",
      "...      ..  ..  ..  ..  \n",
      "4849995   0   0   0   1  \n",
      "4849996   0   0   0   1  \n",
      "4849997   0   0   0   1  \n",
      "4849998   0   0   0   1  \n",
      "4849999   0   0   0   1  \n",
      "\n",
      "[4850000 rows x 21 columns]\n",
      "4850000\n",
      "4850000\n"
     ]
    }
   ],
   "source": [
    "languages = list(set(labels))\n",
    "encoding = { language: number for language, number in zip(languages, range(len(languages)))}\n",
    "# One-hot encode the language\n",
    "y = pd.get_dummies(map(lambda x: encoding[x], labels))\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "print(X.shape[0])\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5a4afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in csv files\n",
    "pd.DataFrame(X).to_csv(\"X.csv\")\n",
    "y.to_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3095ca178695d52cb9a30602b8a9f2323de433ba6e1e7e64a2aa72572452eef0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
